{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import PIL.Image as Image\n",
        "import numpy as np\n",
        "\n",
        "IMAGES_PATH = \"./img/\"\n",
        "\n",
        "ROWS = 2\n",
        "COLUMNS = 4\n",
        "IMAGE_SAVE_PATH = './img/final.png'\n",
        "\n",
        "height = 1280\n",
        "width = 962\n",
        "\n",
        "def biggest_contour(contours):\n",
        "    biggest = np.array([])\n",
        "    max_area = 0\n",
        "    for i in contours:\n",
        "        # Get the area and perimeter of contour\n",
        "        area = cv2.contourArea(i)\n",
        "        peri = cv2.arcLength(i, True)\n",
        "\n",
        "        # Approximate the (closed) curve and get its points\n",
        "        approx = cv2.approxPolyDP(i, 0.02 * peri, True)\n",
        "\n",
        "        # If current contour is bigger than previous one, AND it is a rectangle\n",
        "        if area > max_area and len(approx) == 4:\n",
        "            biggest = approx\n",
        "            max_area = area\n",
        "\n",
        "    # Squeeze to 2D matrix: (4, 1, 2) -> (4, 2)\n",
        "    # biggest = np.squeeze(biggest, axis=1)\n",
        "\n",
        "    return biggest, max_area\n",
        "\n",
        "\n",
        "def reorder(points):\n",
        "    \"\"\"\n",
        "    Reorder the points based on following notation:\n",
        "    (x_min, y_min), (x_max, y_min), (x_min, y_max), (x_max, y_max)\n",
        "    :param points: The 4 points to reorder\n",
        "    :return: The reordered 4 points -> dimension: (4, 1, 2)\n",
        "    \"\"\"\n",
        "    # Squeeze to 2D matrix: (4, 1, 2) -> (4, 2)\n",
        "    points = np.squeeze(points, axis=1)\n",
        "\n",
        "    points_new = np.zeros((4, 1, 2), dtype=np.int32)\n",
        "\n",
        "    # Add the x and y values of all 4 points\n",
        "    add = points.sum(1)\n",
        "\n",
        "    # First point, with smallest x and y coordinates\n",
        "    points_new[0] = points[np.argmin(add)]\n",
        "\n",
        "    # Last point, with largest x and y coordinates\n",
        "    points_new[3] = points[np.argmax(add)]\n",
        "\n",
        "    # Subtract the x and y values of all 4 points\n",
        "    diff = np.diff(points, axis=1)\n",
        "\n",
        "    points_new[1] = points[np.argmin(diff)]\n",
        "    points_new[2] = points[np.argmax(diff)]\n",
        "\n",
        "    return points_new"
      ],
      "metadata": {
        "id": "8dq5DtkxJ-BD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "PATH = \"04.jpg\"\n",
        "\n",
        "\n",
        "def doc_scan_pipeline(input=PATH, output=\"res.jpg\"):\n",
        "    img = cv2.imread(input)\n",
        "\n",
        "    # 0. Convert given image from BGR to RGB format\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    h, w, _ = img.shape\n",
        "    img = cv2.resize(img, (width, height))\n",
        "\n",
        "    # 1. Convert to grayscale\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # 2. Add Gaussian blur\n",
        "    img_blur = cv2.GaussianBlur(img_gray, (5, 5), 1)\n",
        "\n",
        "    # 3. Add Canny edge detection\n",
        "    img_threshold = cv2.Canny(img_blur, 100, 200, L2gradient=True)\n",
        "\n",
        "    # 3.1 Apply dilation\n",
        "    kernel = np.ones((3, 3))\n",
        "    img_threshold = cv2.dilate(img_threshold, kernel, iterations=2)\n",
        "\n",
        "    # 4. Find all the contours\n",
        "    img_contours = img.copy()\n",
        "    img_big_contour = img.copy()\n",
        "    contours, hierarchy = cv2.findContours(img_threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cv2.drawContours(image=img_contours, contours=contours, contourIdx=-1, color=(0, 255, 0), thickness=5)\n",
        "\n",
        "    # 5. Find the biggest contour\n",
        "    biggest, maxArea = biggest_contour(contours)\n",
        "    biggest = reorder(biggest)\n",
        "    cv2.drawContours(image=img_big_contour, contours=biggest, contourIdx=-1, color=(0, 255, 0), thickness=10)\n",
        "\n",
        "    # 5.1 Draw a rectangle, i.e., 4 lines connecting the 4 dots corresponding to the largest contour\n",
        "    pts1 = np.float32(biggest)\n",
        "    pts2 = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
        "\n",
        "    # 6. Image Warp\n",
        "    # 6.1 Calculate a 3x3 perspective transform matrix\n",
        "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
        "\n",
        "    # 6.2 Apply the perspective matrix to the image\n",
        "    img_warp_coloured = cv2.warpPerspective(img, matrix, (width, height))\n",
        "\n",
        "    # Save the document to disk\n",
        "    cv2.imwrite(output, img_warp_coloured)"
      ],
      "metadata": {
        "id": "Juro9QXvHqG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_scan_pipeline()"
      ],
      "metadata": {
        "id": "A5BGqoBVKeVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def stitch_images(image1, image2):\n",
        "    # Загрузка изображений\n",
        "    img1 = cv2.imread(image1)\n",
        "    img2 = cv2.imread(image2)\n",
        "\n",
        "    # Преобразование изображений в черно-белое\n",
        "    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Использование детектора ключевых точек (например, SIFT или ORB)\n",
        "    detector = cv2.ORB_create()\n",
        "    keypoints1, descriptors1 = detector.detectAndCompute(gray1, None)\n",
        "    keypoints2, descriptors2 = detector.detectAndCompute(gray2, None)\n",
        "\n",
        "    # Создание объекта сопоставления\n",
        "    matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "\n",
        "    # Выполнение сопоставления ключевых точек\n",
        "    matches = matcher.match(descriptors1, descriptors2)\n",
        "\n",
        "    # Сортировка сопоставлений по расстоянию\n",
        "    matches = sorted(matches, key=lambda x: x.distance)\n",
        "\n",
        "    # Ограничение количества сопоставлений\n",
        "    max_matches = 100\n",
        "    matches = matches[:max_matches]\n",
        "\n",
        "    # Извлечение координат ключевых точек из сопоставлений\n",
        "    points1 = []\n",
        "    points2 = []\n",
        "    for match in matches:\n",
        "        points1.append(keypoints1[match.queryIdx].pt)\n",
        "        points2.append(keypoints2[match.trainIdx].pt)\n",
        "\n",
        "    # Преобразование точек в массивы NumPy\n",
        "    points1 = np.array(points1)\n",
        "    points2 = np.array(points2)\n",
        "\n",
        "    # Оценка гомографической матрицы\n",
        "    H, _ = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
        "\n",
        "    # Выполнение перспективного преобразования изображения\n",
        "    stitched_image = cv2.warpPerspective(img1, H, (img1.shape[1] + img2.shape[1], img1.shape[0]))\n",
        "    stitched_image[0:img2.shape[0], 0:img2.shape[1]] = img2\n",
        "\n",
        "    return stitched_image\n",
        "\n",
        "# Пример использования функции stitch_images\n",
        "image1 = 'testA1.jpg'\n",
        "image2 = 'testA2.jpg'\n",
        "result = stitch_images(image1, image2)\n",
        "\n",
        "# Сохранение результата\n",
        "cv2.imwrite('result.jpg', result)\n",
        "print(\"Изображения успешно склеены и сохранены в result.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUtPLo-hAd6S",
        "outputId": "86e79481-6453-4b94-bc72-85a87675189f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Изображения успешно склеены и сохранены в result.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "img1 = cv2.imread(\"res0.jpg\")\n",
        "img2 = cv2.imread(\"res1.jpg\")\n",
        "\n",
        "sift = cv2.SIFT_create()\n",
        "kp1, des1 = sift.detectAndCompute(img1, None)\n",
        "kp2, des2 = sift.detectAndCompute(img2, None)\n",
        "\n",
        "\n",
        "matcher = cv2.BFMatcher()\n",
        "matches = matcher.match(des1, des2)\n",
        "\n",
        "matches = [m for m in matches if m.distance < 100]\n",
        "\n",
        "src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
        "dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
        "\n",
        "affine_transform, _ = cv2.estimateAffine2D(src_pts, dst_pts)\n",
        "img1_aligned = cv2.warpAffine(img1, affine_transform, (img1.shape[1], img1.shape[0]))\n",
        "\n",
        "cv2.imwrite('affine.jpg', img1_aligned)\n",
        "\n",
        "\n",
        "alpha = 0.5 # коэффициент смешивания\n",
        "blended_image = cv2.addWeighted(img1_aligned, alpha, img2, 1-alpha, 0)\n",
        "\n",
        "cv2.imwrite('Blended Image.jpg', blended_image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "7b1A7kxzElWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Открываем видеофайл\n",
        "video_path = 'path/to/your/video/file.mp4'  # Укажите путь к вашему видеофайлу\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Проверяем, успешно ли открыт видеофайл\n",
        "if not cap.isOpened():\n",
        "    print(\"Ошибка: не удалось открыть видеофайл\")\n",
        "    exit()\n",
        "\n",
        "# Создаем пустой массив для хранения кадров\n",
        "frames = []\n",
        "\n",
        "# Счетчик кадров\n",
        "frame_count = 0\n",
        "\n",
        "# Читаем кадры из видеофайла, пока видеофайл не закончится\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Пропускаем первые 7 кадров\n",
        "    if frame_count % 8 == 0:\n",
        "        # Преобразуем кадр в оттенки серого, если нужно\n",
        "        # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Добавляем кадр в массив\n",
        "        frames.append(frame)\n",
        "\n",
        "        # Отображаем кадр\n",
        "        cv2.imshow(\"Frame\", frame)\n",
        "\n",
        "    # Прерываем цикл при нажатии клавиши \"q\"\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "# Закрываем окна и освобождаем ресурсы\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Выводим информацию о количестве кадров\n",
        "print(f\"Количество кадров: {len(frames)}\")\n"
      ],
      "metadata": {
        "id": "UjM17ubFA5Ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "BG_COLOR = 209\n",
        "\n",
        "def blank_image(width=1024, height=1024):\n",
        "    img = np.full((height, width, 1), BG_COLOR, np.uint8)\n",
        "    return img\n",
        "\n",
        "def noisy(image):\n",
        "    row, col, ch = image.shape\n",
        "    mean = 0\n",
        "    sigma = 10\n",
        "    gauss = np.random.normal(mean, sigma, (row, col, ch))\n",
        "    gauss = gauss.reshape(row, col, ch)\n",
        "    noisy = gauss + image\n",
        "    return noisy\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    img = blank_image()\n",
        "    cv2.imwrite('out.jpg', noisy(img))"
      ],
      "metadata": {
        "id": "40emN_I5Y68H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}